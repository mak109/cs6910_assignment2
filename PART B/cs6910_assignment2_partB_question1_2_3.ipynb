{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mak109/cs6910_assignment2/blob/main/PART%20B/cs6910_assignment2_partB_question1_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e29e87fc"
      },
      "source": [
        "# Loading and Fine-tuning pretrained Models"
      ],
      "id": "e29e87fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b4cbe4a",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ],
      "id": "8b4cbe4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57958201",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# !pip install wandb -qqq\n",
        "# import wandb\n",
        "# wandb.login()\n",
        "# from wandb.keras import WandbCallback"
      ],
      "id": "57958201"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c739a581"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import wget\n",
        "import os\n",
        "import datetime\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from inspect import *\n",
        "from matplotlib import gridspec\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ],
      "id": "c739a581"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe89a953"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,Sequential,regularizers,optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import * \n",
        "import random\n",
        "random.seed(123)"
      ],
      "id": "fe89a953"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b44f191",
        "outputId": "0b34494d-17fd-499e-c3f7-44bb8d375f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "url='https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "filename = os.path.basename(url)\n",
        "if not os.path.exists(filename) and not os.path.exists(\"inaturalist_12K\"):\n",
        "  filename = wget.download(url)\n",
        "  with ZipFile(filename, 'r') as z:\n",
        "    print('Extracting all the files now...')\n",
        "    z.extractall()\n",
        "    print('Done!')\n",
        "  os.remove(filename)\n",
        "train_dir = 'inaturalist_12K/train'\n",
        "test_dir = 'inaturalist_12K/val'"
      ],
      "id": "7b44f191"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa298523"
      },
      "outputs": [],
      "source": [
        "image_size = (256,256)\n",
        "num_classes = 10"
      ],
      "id": "fa298523"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ad59e2"
      },
      "outputs": [],
      "source": [
        "#Creating dictionary of models based on imagenet \n",
        "model_list = dict()\n",
        "for key,value in getmembers(tf.keras.applications,isfunction):\n",
        "    model_list[key] = value"
      ],
      "id": "47ad59e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94dd721d"
      },
      "outputs": [],
      "source": [
        "#Creating model using pretrained model\n",
        "def CNN(config):\n",
        "    base_model = model_list[config['model']](input_shape=image_size +(3,),include_top=False,weights='imagenet')\n",
        "    base_model.trainable = True #this is important\n",
        "    if(len(base_model.layers) > config['fine_tune_last']):\n",
        "        for layer in base_model.layers[:-config['fine_tune_last']]:\n",
        "            layer.trainable = False    \n",
        "    global_average_layer = layers.GlobalAveragePooling2D()\n",
        "    prediction_layer = layers.Dense(num_classes,activation='softmax')\n",
        "    inputs = layers.Input((image_size[0],image_size[1],3))\n",
        "    input_rescale=layers.Rescaling(1./255)(inputs)\n",
        "    x = base_model(input_rescale)    \n",
        "    x = global_average_layer(x)\n",
        "    x = layers.Dropout(config['dropout'])(x)\n",
        "    outputs = prediction_layer(x)\n",
        "    model = keras.Model(inputs,outputs)\n",
        "    return model"
      ],
      "id": "94dd721d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2531c39f"
      },
      "outputs": [],
      "source": [
        "def train(config_in = None,checkpointing=False):\n",
        "\n",
        "\n",
        "  #Default parameters\n",
        "\n",
        "    config_ = {\n",
        "    \"model\": 'InceptionV3',\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"data_augment\": \"True\",\n",
        "    \"dropout\":0.2,\n",
        "    \"batch_size\":32,\n",
        "    \"fine_tune_last\":20,\n",
        "    \"epochs\":3\n",
        "    }\n",
        "\n",
        "    '''Wandb Configs'''\n",
        "    # wandb.init(config=config_)\n",
        "    # config = wandb.config\n",
        "    #Setting run name for better readability\n",
        "    # wandb.run.name = \"nd_\"+str(config[\"dense_layer_size\"])+\"bs_\"+str(config[\"batch_size\"])+\"ac_\"+str(config[\"activation\"])\n",
        "    #Some data preprocessing and train,val splitting\n",
        "    \n",
        "    #Comment out this code while using wandb\n",
        "    if config_in is not None:\n",
        "          config = config_in\n",
        "    else:\n",
        "          config = config_ #Default Config\n",
        "\n",
        "    val_generator = ImageDataGenerator(dtype=tf.float32,validation_split=0.1,data_format='channels_last').flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size = image_size,\n",
        "        batch_size = config['batch_size'],\n",
        "        color_mode = 'rgb',\n",
        "        class_mode = 'sparse',\n",
        "        shuffle=True,\n",
        "        subset='validation',\n",
        "        seed=123\n",
        "    \n",
        "    )\n",
        "\n",
        "\n",
        "    #Data Augmentation\n",
        "    if config[\"data_augment\"] == 'True':\n",
        "        data_generator = ImageDataGenerator(\n",
        "        rotation_range=50, #random rotation between -50(clockwise) to 50(anti-clockwise) degree\n",
        "        brightness_range=(0.2,0.8), \n",
        "        zoom_range=0.3, #zoom in range from [0.7,1.3]\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        width_shift_range=0.1, #Horizontal Shifting as a ratio of width\n",
        "        height_shift_range=0.2,#Vertical Shifting as a ratio of height\n",
        "        data_format='channels_last',\n",
        "        validation_split=0.1,\n",
        "        dtype=tf.float32\n",
        "        )\n",
        "    else:\n",
        "        data_generator = ImageDataGenerator(\n",
        "            data_format='channels_last',\n",
        "            validation_split=0.1,\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "    #Train set creation after conditional augmentation\n",
        "    train_generator = data_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = config['batch_size'],\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'sparse',\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    seed=123\n",
        "    )\n",
        "    \n",
        "    model = CNN(config)\n",
        "    \n",
        "    model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "        #For checkpointing default value is False\n",
        "    if checkpointing == True:\n",
        "        current_directory = os.getcwd()\n",
        "        final_directory = os.path.join(current_directory, f'models_pretrained_{datetime.datetime.now()}')\n",
        "        if not os.path.exists(final_directory):\n",
        "            os.makedirs(final_directory)\n",
        "        checkpoint_filepath = final_directory\n",
        "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "          filepath=checkpoint_filepath,\n",
        "          save_weights_only=False,\n",
        "          monitor='val_accuracy',\n",
        "          mode='max',\n",
        "          save_best_only=True)\n",
        "          #Fitting Model\n",
        "        history = model.fit(train_generator,\n",
        "          validation_data=val_generator,\n",
        "          epochs=config[\"epochs\"],\n",
        "          verbose=1,\n",
        "          # callbacks = [WandbCallback()] #Used with wandb\n",
        "          callbacks = [model_checkpoint_callback] #Custom callback for checkpointing\n",
        "          )\n",
        "    else:\n",
        "        history = model.fit(train_generator,\n",
        "          validation_data=val_generator,\n",
        "          epochs=config[\"epochs\"],\n",
        "          verbose=1,\n",
        "          # callbacks = [WandbCallback()] #Used with wandb\n",
        "          )\n",
        "    # wandb.finish()\n",
        "    return history,model"
      ],
      "id": "2531c39f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df3d0dc7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history,model = train()"
      ],
      "id": "df3d0dc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "120b17df"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "test_generator = ImageDataGenerator(dtype=tf.float32,validation_split=0.0,data_format='channels_last').flow_from_directory(\n",
        "        'inaturalist_12K/val',\n",
        "        target_size = image_size,\n",
        "        batch_size = 200,\n",
        "        color_mode = 'rgb',\n",
        "        class_mode = 'sparse',\n",
        "        shuffle=False,\n",
        "        seed=123\n",
        "        )\n",
        "loss0, accuracy0 = model.evaluate(test_generator)"
      ],
      "id": "120b17df"
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.savefig('metrics-pretrained.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "miZXZnr_o0RQ"
      },
      "id": "miZXZnr_o0RQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''This section is used for loading the models saved with datetime when checkpointing is True'''\n",
        "# #This can be used when checkpointing is set to True and models are saved in model directory with proper name in the current working directory\n",
        "# model_dir = 'models_pretrained_2022-04-03 00:00:29.823768' #model director name goes here\n",
        "# new_model = tf.keras.models.load_model(model_dir)\n",
        "# # Check its architecture\n",
        "# new_model.summary()"
      ],
      "metadata": {
        "id": "S-plpFkOsEDn"
      },
      "id": "S-plpFkOsEDn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Wandb Sweeps '''\n",
        "# #Sweep configuration for runs\n",
        "# # sweep_config = {\n",
        "# #   \"name\" : \"best-sweep\",\n",
        "# #   \"method\" : \"bayes\",\n",
        "# #   \"metric\" : {\n",
        "# #       \"name\" : \"val_accuracy\",\n",
        "# #       \"goal\" : \"maximize\"\n",
        "# #   },\n",
        "# #   \"parameters\" : {\n",
        "# #     \"epochs\" : {\n",
        "# #       \"values\" : [10,20,30]\n",
        "# #     },\n",
        "# #     \"learning_rate\" :{\n",
        "# #       \"values\" : [1e-3,1e-4]\n",
        "# #     },\n",
        "# #     \"kernel_sizes\":{\n",
        "# #         \"values\" : [[(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
        "# #                     [(3,3),(3,3),(5,5),(7,7),(7,7)],\n",
        "# #                     [(11,11),(11,11),(7,7),(5,5),(3,3)],\n",
        "# #                     [(3,3),(5,5),(7,7),(9,9),(11,11)]]\n",
        "# #     },\n",
        "# #     \"filters_list\":{\n",
        "# #         \"values\" : [[32,32,32,32,32],[256,128,64,32,32],[32,64,64,128,128],[32,64,128,256,512]]\n",
        "# #     },\n",
        "# #     \"weight_decay\":{\n",
        "# #       \"values\": [0,0.0005,0.005]  \n",
        "# #     },\n",
        "# #     \"data_augment\":{\n",
        "# #         \"values\": [\"True\",\"False\"]\n",
        "# #     },\n",
        "# #     \"batch_size\":{\n",
        "# #         \"values\":[32,64]\n",
        "# #     },\n",
        "# #     \"activation\":{\n",
        "# #         \"values\": [\"relu\",\"elu\",\"swish\"]\n",
        "# #     },\n",
        "# #       \"dropout\":{\n",
        "# #           \"values\":[0.0,0.2,0.3]\n",
        "# #       },\n",
        "# #       \"dense_layer_size\":{\n",
        "# #           \"values\":[64,128,256,512]\n",
        "# #       },\n",
        "# #       \"batch_normalization\":{\n",
        "# #           \"values\":[\"True\",\"False\"]\n",
        "# #       }\n",
        "# #   }\n",
        "# # }\n",
        "# sweep_config = {\n",
        "#   \"name\" : \"best-sweep\",\n",
        "#   \"method\" : \"bayes\",\n",
        "#   \"metric\" : {\n",
        "#       \"name\" : \"val_accuracy\",\n",
        "#       \"goal\" : \"maximize\"\n",
        "#   },\n",
        "#   \"parameters\" : {\n",
        "#     \"epochs\" : {\n",
        "#       \"values\" : [30]\n",
        "#     },\n",
        "#     \"learning_rate\" :{\n",
        "#       \"value\" : 1e-4\n",
        "#     },\n",
        "#     \"kernel_sizes\":{\n",
        "#         \"value\" : [(3,3),(3,3),(5,5),(7,7),(9,9)]\n",
        "#     },\n",
        "#     \"filters_list\":{\n",
        "#         \"value\" : [256,128,64,32,16]\n",
        "#     },\n",
        "#     \"weight_decay\":{\n",
        "#       \"value\": 1e-5  \n",
        "#     },\n",
        "#     \"data_augment\":{\n",
        "#         \"value\": \"True\"\n",
        "#     },\n",
        "#     \"batch_size\":{\n",
        "#         \"value\":64\n",
        "#     },\n",
        "#     \"activation\":{\n",
        "#         \"value\": \"gelu\"\n",
        "#     },\n",
        "#       \"dropout\":{\n",
        "#           \"value\":0.3\n",
        "#       },\n",
        "#       \"dense_layer_size\":{\n",
        "#           \"value\":256\n",
        "#       },\n",
        "#       \"batch_normalization\":{\n",
        "#           \"value\":\"True\"\n",
        "#       }\n",
        "#   }\n",
        "# }\n",
        "# sweep_id=wandb.sweep(sweep_config,entity=\"dlstack\",project=\"CS6910-ASSIGNMENT-2\")\n",
        "# wandb.agent(sweep_id, function=train, count=1)"
      ],
      "metadata": {
        "id": "QfDuh5aysXsg"
      },
      "id": "QfDuh5aysXsg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "cs6910_assignment2_partB_question1_2_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}