{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mak109/cs6910_assignment2/blob/main/PART%20A/cs6910_assignment2_partA_question5_guided_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guided Backpropagation Implementation\n",
        "In  question 5 we implemented the following things\n",
        "- Guided Backprop on CONV5 layer\n",
        "- Activations visualized for ten neurons(or feature maps) for CONV5 layer\n",
        "\n"
      ],
      "metadata": {
        "id": "Clf5l4BdAmjX"
      },
      "id": "Clf5l4BdAmjX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4cbe4a",
      "metadata": {
        "scrolled": false,
        "id": "8b4cbe4a",
        "outputId": "b7c066e2-b553-4f30-dc0c-d58f1bf4f187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages (3.2)\r\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57958201",
      "metadata": {
        "scrolled": true,
        "id": "57958201",
        "outputId": "826f4eaa-60be-4d8b-e3c1-584be3cccc7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmak109\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21c9ef3",
      "metadata": {
        "id": "a21c9ef3"
      },
      "outputs": [],
      "source": [
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c739a581",
      "metadata": {
        "id": "c739a581"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import wget\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from matplotlib import gridspec\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe89a953",
      "metadata": {
        "id": "fe89a953"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,Sequential,regularizers,optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b44f191",
      "metadata": {
        "id": "7b44f191"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "url='https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "filename = os.path.basename(url)\n",
        "\n",
        "if not os.path.exists(filename) and not os.path.exists(\"inaturalist_12K\"):\n",
        "  filename = wget.download(url)\n",
        "  with ZipFile(filename, 'r') as zip:\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')\n",
        "  os.remove(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa298523",
      "metadata": {
        "id": "fa298523"
      },
      "outputs": [],
      "source": [
        "image_size = (256,256)\n",
        "num_layers = 5\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e4b43d",
      "metadata": {
        "scrolled": true,
        "id": "74e4b43d"
      },
      "outputs": [],
      "source": [
        "# tf.debugging.set_log_device_placement(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1b05f7",
      "metadata": {
        "id": "fb1b05f7"
      },
      "outputs": [],
      "source": [
        "def CNN(config):\n",
        "    model = Sequential([\n",
        "        layers.Input((image_size[0],image_size[1],3)),\n",
        "        layers.Rescaling(1./255)\n",
        "        ])\n",
        "    \n",
        "    for l in range(num_layers):\n",
        "        model.add(layers.Conv2D(filters=config[\"filters_list\"][l],kernel_size=(config[\"kernel_sizes\"][l][0],config[\"kernel_sizes\"][l][1]),\n",
        "                        activation=config[\"activation\"],padding=\"same\",kernel_regularizer=regularizers.l2(config[\"weight_decay\"])))\n",
        "        if config[\"batch_normalization\"] == 'True':\n",
        "            model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(config[\"dense_layer_size\"],activation=config[\"activation\"],kernel_regularizer=regularizers.l2(config[\"weight_decay\"])))\n",
        "    model.add(layers.Dropout(config[\"dropout\"]))\n",
        "\n",
        "    model.add(layers.Dense(num_classes,activation=\"softmax\"))\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0dd8e7",
      "metadata": {
        "scrolled": true,
        "id": "7d0dd8e7",
        "outputId": "5f326305-6f12-4a76-f7f7-dcc8b8130102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# best_test_run_id = \"8ohaf75c\"\n",
        "test_run_id = \"vyo6dtkg\"\n",
        "api = wandb.Api()\n",
        "run = api.run(\"dlstack/CS6910-ASSIGNMENT-2/\"+test_run_id)\n",
        "if os.path.exists('model-best.h5'):\n",
        "    os.remove('model-best.h5')\n",
        "model_weights = wandb.restore(\"model-best.h5\",run_path=\"dlstack/CS6910-ASSIGNMENT-2/\"+test_run_id)\n",
        "config = run.config\n",
        "\n",
        "model = CNN(config)\n",
        "model.load_weights(model_weights.name)\n",
        "test_generator = ImageDataGenerator(dtype=tf.float32,validation_split=0.0,data_format='channels_last').flow_from_directory(\n",
        "        'inaturalist_12K/val',\n",
        "        target_size = image_size,\n",
        "        batch_size = config['batch_size'],\n",
        "        color_mode = 'rgb',\n",
        "        class_mode = 'sparse',\n",
        "        seed=123\n",
        "        )\n",
        "test_generator_ = test_generator\n",
        "images,labels = next(iter(test_generator_))\n",
        "# model.compile(\n",
        "#     optimizer=optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
        "#     loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=['accuracy']\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02d5a10",
      "metadata": {
        "id": "e02d5a10"
      },
      "outputs": [],
      "source": [
        "class_names =list(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27b9d671",
      "metadata": {
        "id": "27b9d671"
      },
      "outputs": [],
      "source": [
        "@tf.custom_gradient\n",
        "def guidedRelu(x):\n",
        "    def grad(dy):\n",
        "        return tf.cast(dy>0,\"float32\") * tf.cast(x>0, \"float32\") * dy\n",
        "    return tf.nn.relu(x), grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4175ac05",
      "metadata": {
        "id": "4175ac05"
      },
      "outputs": [],
      "source": [
        "layer_activation_list = [layer.activation for layer in model.layers if hasattr(layer,'activation')]\n",
        "activation_model = tf.keras.models.Model([model.inputs],[model.layers[9].output])\n",
        "for activation in layer_activation_list:\n",
        "    if activation == tf.keras.activations.relu:\n",
        "        activation = guidedRelu\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96a4036",
      "metadata": {
        "id": "a96a4036"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    inputs = tf.cast(images,tf.float32)\n",
        "    tape.watch(inputs)\n",
        "    outputs = activation_model(inputs)\n",
        "grads = tape.gradient(outputs,inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87df07aa",
      "metadata": {
        "id": "87df07aa"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"CS6910-ASSIGNMENT-2\",entity=\"dlstack\")\n",
        "plt.figure(figsize=(200,200))\n",
        "plt.title(\"Activations of CONV5 layer\")\n",
        "g = gridspec.GridSpec(12,10,hspace=0.1,wspace=0.1,left=0.8,right=0.9,top=0.9,bottom=0.8)\n",
        "for j in range(10):\n",
        "    ax = plt.subplot(g[0,j])\n",
        "    ax.imshow(images[j].astype(\"uint8\"))\n",
        "    ax.set_title(class_names[labels[j].astype(\"int\")])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    for i in range(10):\n",
        "        ax = plt.subplot(g[i+1,j])\n",
        "        ax.imshow(outputs.numpy()[j,:,:,i],cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "    gb_viz = grads[j]\n",
        "    gb_viz = np.dstack((\n",
        "                gb_viz[:, :, 0],\n",
        "                gb_viz[:, :, 1],\n",
        "                gb_viz[:, :, 2],\n",
        "            ))       \n",
        "    gb_viz -= np.min(gb_viz)\n",
        "    gb_viz /= gb_viz.max()\n",
        "\n",
        "    ax = plt.subplot(g[11,j])\n",
        "    ax.imshow(gb_viz)\n",
        "    ax.axis(\"off\")\n",
        "plt.savefig(\"guided_backprop.jpg\",bbox_inches=\"tight\")\n",
        "wandb.run.name= \"guided-backprop\"\n",
        "wandb.log({\"Guided backprop on 10 images for CONV5 layer\":wandb.Image(\"guided_backprop.jpg\")})\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "cs6910_assignment2_partA_question5_guided_backprop.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}